# üèóÔ∏è Guia de Arquitetura - Pipeline Sa√∫de RJ

## Vis√£o Geral da Arquitetura

O Pipeline Sa√∫de RJ implementa uma arquitetura moderna de dados baseada em cloud, seguindo as melhores pr√°ticas de Data Engineering com separa√ß√£o clara de responsabilidades.

## Componentes da Arquitetura

### 1. Camada de Extra√ß√£o (Extract Layer)

**Responsabilidade**: Coleta de dados de fontes externas

```mermaid
graph LR
    A[DataRio API] --> E[etl_extract.py]
    B[DataSUS API] --> E
    C[IBGE API] --> E
    E --> D[Google Cloud Storage]
```

**Tecnologias**:
- Python 3.9+ com requests
- Pandas para manipula√ß√£o de dados
- Google Cloud Storage SDK

**Padr√µes Implementados**:
- Retry com backoff exponencial
- Logging estruturado
- Valida√ß√£o de schema
- Tratamento de erros gracioso

### 2. Camada de Armazenamento (Storage Layer)

**Data Lake**: Google Cloud Storage
- Bucket: `data-saude-brutos`
- Estrutura: `raw/YYYY/MM/DD/dataset.parquet`
- Formato: Parquet (otimizado para analytics)

**Data Warehouse**: BigQuery
- Dataset Raw: `brutos_saude`
- Dataset Processado: `model_saude`
- Particionamento por data de extra√ß√£o

### 3. Camada de Transforma√ß√£o (Transform Layer)

**dbt (Data Build Tool)**

```
models/
‚îú‚îÄ‚îÄ stg/           # Staging - Limpeza e Tipagem
‚îú‚îÄ‚îÄ core/          # Core - M√©tricas e Agrega√ß√µes  
‚îî‚îÄ‚îÄ marts/         # Marts - Tabelas para Consumo
```

**Estrat√©gia de Materializa√ß√£o**:
- **Staging**: Views (transforma√ß√µes leves)
- **Core**: Tables (agrega√ß√µes complexas)
- **Marts**: Tables (otimizadas para BI)

### 4. Camada de Orquestra√ß√£o (Orchestration Layer)

**Apache Airflow**

```python
DAG: pipeline_saude_rj
‚îú‚îÄ‚îÄ check_prerequisites
‚îú‚îÄ‚îÄ extract_health_data  
‚îú‚îÄ‚îÄ sensor_check_files
‚îú‚îÄ‚îÄ load_to_bigquery
‚îú‚îÄ‚îÄ run_dbt_models
‚îú‚îÄ‚îÄ run_quality_tests
‚îî‚îÄ‚îÄ send_notifications
```

**Caracter√≠sticas**:
- Schedule: Di√°rio √†s 6:00 AM
- Retry: 2 tentativas com delay de 5min
- SLA: 2 horas m√°ximo
- Alertas por email em falhas

### 5. Camada de Qualidade (Quality Layer)

**Great Expectations**
- Valida√ß√£o de schema
- Testes de integridade referencial
- Verifica√ß√£o de completude
- Alertas de anomalias

**Testes dbt**
- Unique constraints
- Not null validations
- Accepted values
- Range validations

## Fluxo de Dados Detalhado

### Fluxo Principal (Happy Path)

1. **06:00** - Airflow inicia DAG
2. **06:05** - Extra√ß√£o das APIs
   - DataRio: Unidades e atendimentos
   - DataSUS: Estat√≠sticas complementares
   - IBGE: Dados demogr√°ficos
3. **06:15** - Upload para GCS em formato parquet
4. **06:20** - Sensor verifica arquivos criados
5. **06:25** - Load para BigQuery (tabelas raw)
6. **06:30** - dbt executa transforma√ß√µes
   - Staging: Limpeza e tipagem
   - Core: M√©tricas e agrega√ß√µes
   - Marts: Tabela final do dashboard
7. **06:45** - Testes de qualidade
8. **06:50** - Atualiza√ß√£o de estat√≠sticas BQ
9. **06:55** - Notifica√ß√£o de sucesso

### Tratamento de Erros

**Estrat√©gias de Recupera√ß√£o**:
- Retry autom√°tico (2x)
- Fallback para dados do dia anterior
- Alertas imediatos para time de dados
- Rollback de transforma√ß√µes em caso de falha

**Monitoramento**:
- Logs centralizados no Google Cloud Logging
- M√©tricas de performance no Airflow
- Alertas proativos via email/Slack

## Padr√µes de Design Implementados

### 1. ELT (Extract, Load, Transform)

Optamos por ELT ao inv√©s de ETL tradicional:
- **Vantagem**: Flexibilidade para mudan√ßas
- **Benef√≠cio**: Poder computacional do BigQuery
- **Resultado**: Transforma√ß√µes mais r√°pidas

### 2. Medallion Architecture (Bronze, Silver, Gold)

```
Bronze (Raw)     ‚Üí Silver (Core)    ‚Üí Gold (Marts)
brutos_saude.*   ‚Üí model_saude.*    ‚Üí dashboards
```

### 3. Idempot√™ncia

Todas as opera√ß√µes s√£o idempotentes:
- Mesma execu√ß√£o = mesmo resultado
- Permite re-execu√ß√£o segura
- Facilita debugging e recupera√ß√£o

### 4. Schema Evolution

**Backward Compatibility**:
- Adi√ß√£o de colunas opcionais
- Renomea√ß√£o com aliases
- Depreca√ß√£o gradual

## Otimiza√ß√µes de Performance

### BigQuery

**Particionamento**:
```sql
PARTITION BY DATE(data_extracao)
```

**Clustering**:
```sql  
CLUSTER BY regiao, tipo_unidade
```

**Materializa√ß√£o Inteligente**:
- Views para transforma√ß√µes simples
- Tables para agrega√ß√µes pesadas
- Incremental para grandes volumes

### dbt

**Configura√ß√µes de Performance**:
```yaml
models:
  saude_rj:
    core:
      +materialized: table
      +partition_by: {"field": "data_referencia", "data_type": "date"}
      +cluster_by: ["regiao", "tipo_unidade"]
```

## Seguran√ßa e Compliance

### Controle de Acesso

**IAM Roles**:
- `pipeline-saude-sa`: Service account do pipeline
- `data-viewer`: Acesso read-only aos dados
- `data-analyst`: Acesso completo aos marts

**Princ√≠pio do Menor Privil√©gio**:
- Cada componente tem apenas as permiss√µes necess√°rias
- Rota√ß√£o regular de credenciais
- Auditoria de acessos

### Prote√ß√£o de Dados

**Dados Sens√≠veis**:
- Anonimiza√ß√£o de informa√ß√µes pessoais
- Hasheamento de identificadores √∫nicos
- Mascaramento em ambientes n√£o-produ√ß√£o

## Escalabilidade

### Horizontal Scaling

**Airflow**:
- Kubernetes Executor para paraleliza√ß√£o
- Auto-scaling baseado na carga
- Separa√ß√£o de workers por tipo de task

**BigQuery**:
- Auto-scaling nativo
- Slots din√¢micos
- Otimiza√ß√£o autom√°tica de queries

### Vertical Scaling

**Recursos Computacionais**:
- Ajuste autom√°tico de mem√≥ria
- CPU scaling baseado na demanda
- Storage scaling transparente

## Disaster Recovery

### Backup Strategy

**Dados**:
- Cross-region replication no GCS
- Snapshots di√°rios do BigQuery
- Versionamento de datasets

**C√≥digo**:
- Git com m√∫ltiplos remotes
- Container registry backup
- Infraestrutura como c√≥digo (Terraform)

### Recovery Time Objective (RTO)

- **RTO**: 4 horas m√°ximo
- **RPO**: 24 horas (dados di√°rios)
- **Disponibilidade**: 99.9% uptime

## Governan√ßa de Dados

### Data Lineage

**Ferramentas**:
- dbt docs para lineage autom√°tico
- Data Catalog do Google Cloud
- Mapeamento end-to-end

### Qualidade de Dados

**M√©tricas**:
- Completude: 95% m√≠nimo
- Precis√£o: 98% m√≠nimo  
- Consist√™ncia: 100% obrigat√≥rio
- Atualidade: 24h m√°ximo

## Custos e ROI

### Otimiza√ß√£o de Custos

**BigQuery**:
- On-demand pricing otimizado
- Slots commitments para workloads previs√≠veis
- Lifecycle policies no GCS

**Monitoramento**:
- Budget alerts configurados
- Cost breakdown por componente
- Otimiza√ß√£o cont√≠nua de queries

### ROI Estimado

**Benef√≠cios**:
- Redu√ß√£o de 70% no tempo de an√°lise
- Alertas proativos economizam recursos
- Insights para otimiza√ß√£o do sistema de sa√∫de

## Roadmap T√©cnico

### Fase 2 (Q1 2024)
- [ ] Streaming com Pub/Sub
- [ ] ML para previs√£o de demanda
- [ ] Data Mesh implementation

### Fase 3 (Q2 2024)
- [ ] Real-time alerting
- [ ] Advanced analytics com Vertex AI
- [ ] Multi-cloud strategy

## Contatos T√©cnicos

**Arquiteto de Dados**: Ingrid Lima
**Email**: ingrid@exemplo.com
**Slack**: #data-engineering-team