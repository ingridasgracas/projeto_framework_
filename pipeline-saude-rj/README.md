# ğŸ¥ Pipeline de Dados PÃºblicos â€” SaÃºde no Rio

> **Pipeline automatizado de dados sobre atendimentos de saÃºde na cidade do Rio de Janeiro**  
> Arquitetura moderna usando Data Lake + Data Warehouse para monitorar indicadores de saÃºde pÃºblica

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![dbt](https://img.shields.io/badge/dbt-1.5+-orange.svg)](https://www.getdbt.com/)
[![Airflow](https://img.shields.io/badge/Airflow-2.6+-red.svg)](https://airflow.apache.org/)
[![BigQuery](https://img.shields.io/badge/BigQuery-GCP-blue.svg)](https://cloud.google.com/bigquery)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ¯ Objetivo

Construir um pipeline de dados automatizado que coleta, transforma e publica indicadores sobre atendimentos de saÃºde na cidade do Rio, permitindo:

- ğŸ“Š Monitorar tempo mÃ©dio de espera em unidades pÃºblicas e privadas
- ğŸ¥ Acompanhar disponibilidade de leitos e ocupaÃ§Ã£o hospitalar  
- ğŸ—ºï¸ Comparar indicadores por regiÃ£o da cidade
- âš¡ Detectar gargalos e alertas em tempo real
- ğŸ“ˆ Gerar insights para melhoria do sistema de saÃºde

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   APIs PÃºblicas â”‚    â”‚  Google Cloud    â”‚    â”‚   Airflow       â”‚
â”‚                 â”‚    â”‚   Storage        â”‚    â”‚  OrquestraÃ§Ã£o   â”‚
â”‚ â€¢ DataRio       â”‚â”€â”€â”€â–¶â”‚                  â”‚â”€â”€â”€â–¶â”‚                 â”‚
â”‚ â€¢ DataSUS       â”‚    â”‚  (Dados Brutos)  â”‚    â”‚  â€¢ ETL Daily    â”‚
â”‚ â€¢ IBGE          â”‚    â”‚                  â”‚    â”‚  â€¢ dbt Run      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â€¢ Data Quality â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  Looker Studio  â”‚    â”‚    BigQuery      â”‚           â”‚
â”‚                 â”‚    â”‚                  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â€¢ Dashboards    â”‚â—€â”€â”€â”€â”‚ â€¢ Data Warehouse â”‚
â”‚ â€¢ Alertas       â”‚    â”‚ â€¢ dbt Models     â”‚
â”‚ â€¢ RelatÃ³rios    â”‚    â”‚ â€¢ Marts          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Stack TecnolÃ³gica

| Camada | Ferramenta | FunÃ§Ã£o |
|--------|------------|---------|
| **ExtraÃ§Ã£o** | Python + Requests | Coleta dados das APIs pÃºblicas |
| **Armazenamento** | Google Cloud Storage | Data Lake para dados brutos |
| **TransformaÃ§Ã£o** | dbt + BigQuery | Limpeza, modelagem e mÃ©tricas |
| **OrquestraÃ§Ã£o** | Apache Airflow | AutomaÃ§Ã£o e monitoramento |
| **VisualizaÃ§Ã£o** | Looker Studio | Dashboards e relatÃ³rios |
| **Qualidade** | Great Expectations | ValidaÃ§Ã£o e testes de dados |

## ğŸ“ Estrutura do Projeto

```
pipeline-saude-rj/
â”œâ”€â”€ airflow/                    # OrquestraÃ§Ã£o
â”‚   â””â”€â”€ dag_saude_rj.py        # DAG principal
â”œâ”€â”€ dbt/                        # TransformaÃ§Ãµes
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ stg/               # Staging (limpeza)
â”‚   â”‚   â”œâ”€â”€ core/              # Core (mÃ©tricas)
â”‚   â”‚   â””â”€â”€ marts/             # Marts (dashboard)
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â””â”€â”€ profiles.yml
â”œâ”€â”€ etl/                        # Scripts ETL
â”‚   â”œâ”€â”€ etl_extract.py         # ExtraÃ§Ã£o de dados
â”‚   â””â”€â”€ etl_load_bq.py         # Carregamento BigQuery
â”œâ”€â”€ tests/                      # Testes de qualidade
â”œâ”€â”€ docker/                     # ContainerizaÃ§Ã£o
â”œâ”€â”€ docs/                       # DocumentaÃ§Ã£o
â”œâ”€â”€ config/                     # ConfiguraÃ§Ãµes
â”œâ”€â”€ requirements.txt            # DependÃªncias Python
â”œâ”€â”€ setup.py                   # Script de instalaÃ§Ã£o
â””â”€â”€ README.md                  # Este arquivo
```

## ğŸš€ Quick Start

### 1. PrÃ©-requisitos

- Python 3.9+
- Google Cloud Platform (conta ativa)
- Docker & Docker Compose
- Git

### 2. InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/pipeline-saude-rj.git
cd pipeline-saude-rj

# Execute o setup automÃ¡tico
python setup.py

# Configure as credenciais
cp .env.template .env
# Edite o arquivo .env com suas credenciais GCP
```

### 3. ConfiguraÃ§Ã£o GCP

```bash
# Instale e configure Google Cloud CLI
gcloud auth login
gcloud config set project SEU_PROJECT_ID

# Crie service account
gcloud iam service-accounts create pipeline-saude-sa

# Download das credenciais
gcloud iam service-accounts keys create credentials.json \
  --iam-account=pipeline-saude-sa@SEU_PROJECT_ID.iam.gserviceaccount.com
```

### 4. Executar Pipeline

```bash
# Teste extraÃ§Ã£o local
cd etl
python etl_extract.py

# Teste dbt
cd ../dbt
dbt run --profiles-dir .

# Executar com Airflow (Docker)
docker-compose up -d
```

## ğŸ“Š Fontes de Dados

### DataRio - Portal de Dados Abertos
- **URL**: https://www.dados.rio/dataset
- **Dados**: Unidades de saÃºde, filas, atendimentos
- **FrequÃªncia**: DiÃ¡ria
- **Formato**: JSON via API REST

### DataSUS - Sistema Ãšnico de SaÃºde
- **URL**: https://datasus.saude.gov.br/
- **Dados**: EstatÃ­sticas nacionais e regionais
- **FrequÃªncia**: Mensal/Anual
- **Formato**: CSV e APIs pÃºblicas

### IBGE - Demografia e Contexto
- **URL**: https://servicodados.ibge.gov.br/api/
- **Dados**: PopulaÃ§Ã£o, renda, territÃ³rios
- **FrequÃªncia**: Anual
- **Formato**: JSON via API REST

## ğŸ”„ Fluxo de Dados

### 1. **ExtraÃ§Ã£o (06:00 diÃ¡rio)**
```python
# Coleta dados das APIs
python etl/etl_extract.py
# â†’ Salva em GCS: gs://data-saude-brutos/raw/YYYY/MM/DD/
```

### 2. **Carregamento (06:15)**
```python
# Upload para BigQuery
python etl/etl_load_bq.py
# â†’ Tabelas: brutos_saude.*
```

### 3. **TransformaÃ§Ã£o (06:30)**
```bash
# Executa modelos dbt
dbt run --profiles-dir dbt/
# â†’ Layers: staging â†’ core â†’ marts
```

### 4. **Qualidade (07:00)**
```python
# ValidaÃ§Ãµes automÃ¡ticas
great_expectations checkpoint run pipeline_checkpoint
```

### 5. **Dashboard (07:15)**
- Looker Studio atualiza automaticamente
- Alertas enviados via email/Slack

## ğŸ“ˆ MÃ©tricas e KPIs

### Indicadores Principais
- **Tempo MÃ©dio de Espera**: Por regiÃ£o e tipo de unidade
- **Taxa de OcupaÃ§Ã£o**: Leitos gerais e UTI
- **Volume de Atendimentos**: SUS vs. Privado
- **Disponibilidade**: Vagas por especialidade

### Alertas Automatizados
- ğŸ”´ **CrÃ­tico**: OcupaÃ§Ã£o > 95% ou espera > 2h
- ğŸŸ¡ **AtenÃ§Ã£o**: OcupaÃ§Ã£o > 80% ou espera > 1h  
- ğŸŸ¢ **Normal**: Indicadores dentro da meta

## ğŸ” Modelos de Dados

### Camada Staging (stg_*)
- `stg_atendimentos`: Limpeza e tipagem de atendimentos
- `stg_unidades_saude`: Cadastro de unidades normalizado
- `stg_leitos`: Disponibilidade e ocupaÃ§Ã£o de leitos

### Camada Core (core_*)
- `core_metricas_atendimento`: AgregaÃ§Ãµes por unidade/perÃ­odo
- `core_ocupacao_leitos`: MÃ©tricas de ocupaÃ§Ã£o hospitalar
- `core_indicadores_saude`: KPIs consolidados por regiÃ£o

### Camada Marts (marts_*)
- `marts_dashboard_saude`: Tabela final para visualizaÃ§Ã£o

## ğŸ§ª Qualidade de Dados

### ValidaÃ§Ãµes Implementadas
- âœ… Completude: Campos obrigatÃ³rios nÃ£o-nulos
- âœ… ConsistÃªncia: ValidaÃ§Ã£o de domÃ­nios e ranges
- âœ… PrecisÃ£o: VerificaÃ§Ã£o de coordenadas geogrÃ¡ficas
- âœ… Atualidade: Dados atualizados nas Ãºltimas 24h

### Testes dbt
```sql
-- Exemplo de teste
{{ config(severity='error') }}
SELECT * FROM {{ ref('stg_atendimentos') }}
WHERE tempo_espera_minutos < 0 OR tempo_espera_minutos > 600
```

## ğŸ³ Deploy com Docker

```yaml
# docker-compose.yml
version: '3.8'
services:
  airflow-webserver:
    image: apache/airflow:2.6.3
    environment:
      - LOAD_EX=n
      - EXECUTOR=Local
    volumes:
      - ./airflow:/opt/airflow/dags
      - ./etl:/opt/airflow/dags/etl
      - ./dbt:/opt/airflow/dags/dbt
```

```bash
# Executar em produÃ§Ã£o
docker-compose up -d

# Acessar interface
open http://localhost:8080
```

## ğŸ“Š Dashboard Looker Studio

### VisualizaÃ§Ãµes Principais
1. **Mapa de Calor**: Tempo de espera por regiÃ£o
2. **SÃ©rie Temporal**: EvoluÃ§Ã£o dos indicadores
3. **Comparativo**: SUS vs. Privado
4. **Alertas**: Status crÃ­tico por unidade
5. **Filtros**: PerÃ­odo, regiÃ£o, tipo de atendimento

### URL do Dashboard
ğŸ”— [Dashboard SaÃºde RJ](https://lookerstudio.google.com/seu-dashboard)

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudanÃ§as (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Abra um Pull Request

## ğŸ“‹ Roadmap

- [x] âœ… Pipeline bÃ¡sico ETL
- [x] âœ… Modelos dbt estruturados  
- [x] âœ… OrquestraÃ§Ã£o Airflow
- [ ] ğŸ”„ IntegraÃ§Ã£o Great Expectations
- [ ] ğŸ“± Alertas Slack/Teams
- [ ] ğŸ” AutenticaÃ§Ã£o OAuth
- [ ] ğŸ“Š ML para previsÃ£o de demanda
- [ ] ğŸš€ Deploy GCP Cloud Composer

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja [LICENSE](LICENSE) para mais detalhes.

## ğŸ‘¥ Autores

- **Seu Nome** - *Engenheira de Dados* - [GitHub](https://github.com/seu-usuario)

## ğŸ™ Agradecimentos

- Prefeitura do Rio de Janeiro pelos dados abertos
- Comunidade dbt pelos templates e boas prÃ¡ticas
- Apache Airflow pela orquestraÃ§Ã£o robusta

---

**ğŸ’¡ Dica**: Este projeto pode ser adaptado para outras cidades ou domÃ­nios de saÃºde pÃºblica. Fork e customize conforme sua necessidade!

## ğŸ“ Suporte

- ğŸ“§ Email: seu-email@exemplo.com
- ğŸ’¬ Issues: [GitHub Issues](https://github.com/seu-usuario/pipeline-saude-rj/issues)
- ğŸ“– Wiki: [DocumentaÃ§Ã£o Completa](https://github.com/seu-usuario/pipeline-saude-rj/wiki)